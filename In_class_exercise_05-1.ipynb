{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
    "\n",
    "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
    "\n",
    "Algorithms:\n",
    "\n",
    "(1) MultinominalNB\n",
    "\n",
    "(2) SVM \n",
    "\n",
    "(3) KNN \n",
    "\n",
    "(4) Decision tree\n",
    "\n",
    "(5) Random Forest\n",
    "\n",
    "(6) XGBoost\n",
    "\n",
    "Evaluation measurement:\n",
    "\n",
    "(1) Accuracy\n",
    "\n",
    "(2) Recall\n",
    "\n",
    "(3) Precison \n",
    "\n",
    "(4) F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-55eb1155bfc9>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_data = pd.read_csv('stsa-train.txt', sep = 'delimiter=', header = None, names = ['review'])\n",
      "<ipython-input-1-55eb1155bfc9>:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_data = pd.read_csv('stsa-test.txt', sep = 'delimiter=', header = None, names = ['review'])\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# read dataset\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('stsa-train.txt', sep = 'delimiter=', header = None, names = ['review'])\n",
    "train_data = train_data['review'].str.split(' ', 1, expand = True)\n",
    "train_data.columns = ['sentiment', 'review']\n",
    "\n",
    "test_data = pd.read_csv('stsa-test.txt', sep = 'delimiter=', header = None, names = ['review'])\n",
    "test_data = test_data['review'].str.split(' ', 1, expand = True)\n",
    "test_data.columns = ['sentiment', 'review']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>apparently reassembled from the cutting-room f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             review\n",
       "0         1  a stirring , funny and finally transporting re...\n",
       "1         0  apparently reassembled from the cutting-room f...\n",
       "2         0  they presume their audience wo n't sit still f...\n",
       "3         1  this is a visually stunning rumination on love...\n",
       "4         1  jonathan parker 's bartleby should have been t..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>we never really feel involved with the story ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>this is one of polanski 's best films .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             review\n",
       "0         0     no movement , no yuks , not much of anything .\n",
       "1         0  a gob of drivel so sickly sweet , even the eag...\n",
       "2         0  gangs of new york is an unapologetic mess , wh...\n",
       "3         0  we never really feel involved with the story ,...\n",
       "4         1            this is one of polanski 's best films ."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ttp0037\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ttp0037\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stopword = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "def data_cleaning(text):\n",
    "  text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "  text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text)\n",
    "  tokens = re.split('\\W+',text)\n",
    "  text = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 13343)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>100minute</th>\n",
       "      <th>103minute</th>\n",
       "      <th>10course</th>\n",
       "      <th>10th</th>\n",
       "      <th>10thgrade</th>\n",
       "      <th>10year</th>\n",
       "      <th>10yearold</th>\n",
       "      <th>112minute</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>ziyi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombieland</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>élan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             100minute  103minute  10course  10th  10thgrade  10year  \\\n",
       "0  0.000000        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "1  0.048154        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "2  0.029784        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "3  0.049596        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "4  0.048782        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "\n",
       "   10yearold  112minute   12  ...  ziyi  zoe  zombie  zombieland  zone  \\\n",
       "0        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "1        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "2        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "3        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "4        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "\n",
       "   zoning  zoom  zwick  zzzzzzzzz  élan  \n",
       "0     0.0   0.0    0.0        0.0   0.0  \n",
       "1     0.0   0.0    0.0        0.0   0.0  \n",
       "2     0.0   0.0    0.0        0.0   0.0  \n",
       "3     0.0   0.0    0.0        0.0   0.0  \n",
       "4     0.0   0.0    0.0        0.0   0.0  \n",
       "\n",
       "[5 rows x 13343 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting train_data into numerical usinf TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(analyzer = data_cleaning)\n",
    "X_train_tfidf = tfidf_vector.fit_transform(train_data['review'])\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# saving the td-idf values in a dataframe\n",
    "X_train_tfidf_df=pd.DataFrame(X_train_tfidf.toarray())\n",
    "X_train_tfidf_df.columns=tfidf_vector.get_feature_names()\n",
    "X_train_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1821, 6357)\n"
     ]
    }
   ],
   "source": [
    "# Converting test_data into numerical usinf TF-IDF\n",
    "X_test_tfidf = tfidf_vector.fit_transform(test_data['review'])\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning algorithms\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "svm = LinearSVC()\n",
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5536, 13343) (5536,)\n",
      "(1384, 13343) (1384,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing vars (80% train and 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf_df, train_data['sentiment'].values, test_size = 0.2, random_state = 42)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7955202312138728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77       671\n",
      "           1       0.76      0.88      0.82       713\n",
      "\n",
      "    accuracy                           0.80      1384\n",
      "   macro avg       0.80      0.79      0.79      1384\n",
      "weighted avg       0.80      0.80      0.79      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_mnb = mnb.fit(X_train, y_train)\n",
    "prediction_mnb = model_mnb.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_mnb,y_test))\n",
    "print(classification_report(y_test,prediction_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the model\n",
    "plt.scatter(y_test, prediction_mnb)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinominalNB: 0.7247054530288813\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(mnb, X_test, y_test, cv=10)\n",
    "print(\"MultinominalNB:\",scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.791907514450867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       671\n",
      "           1       0.78      0.83      0.80       713\n",
      "\n",
      "    accuracy                           0.79      1384\n",
      "   macro avg       0.79      0.79      0.79      1384\n",
      "weighted avg       0.79      0.79      0.79      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_svm = svm.fit(X_train,y_train)\n",
    "prediction_svm = model_svm.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_svm, y_test))\n",
    "print(classification_report(y_test, prediction_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.7348034615785632\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(svm, X_test, y_test, cv=10)\n",
    "print(\"SVM:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.740606936416185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       671\n",
      "           1       0.74      0.77      0.75       713\n",
      "\n",
      "    accuracy                           0.74      1384\n",
      "   macro avg       0.74      0.74      0.74      1384\n",
      "weighted avg       0.74      0.74      0.74      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_knn = knn.fit(X_train,y_train)\n",
    "prediction_knn = model_knn.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_knn, y_test))\n",
    "print(classification_report(y_test, prediction_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.6675737670732979\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(knn, X_test, y_test, cv=10)\n",
    "print(\"KNN:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.653179190751445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63       671\n",
      "           1       0.65      0.70      0.67       713\n",
      "\n",
      "    accuracy                           0.65      1384\n",
      "   macro avg       0.65      0.65      0.65      1384\n",
      "weighted avg       0.65      0.65      0.65      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_dt = dt.fit(X_train,y_train)\n",
    "prediction_dt = model_dt.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_dt, y_test))\n",
    "print(classification_report(y_test, prediction_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.6177458033573142\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(dt, X_test, y_test, cv=10)\n",
    "print(\"Decision Tree:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7420520231213873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71       671\n",
      "           1       0.72      0.82      0.77       713\n",
      "\n",
      "    accuracy                           0.74      1384\n",
      "   macro avg       0.75      0.74      0.74      1384\n",
      "weighted avg       0.75      0.74      0.74      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_rf = rf.fit(X_train,y_train)\n",
    "prediction_rf = model_rf.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_rf, y_test))\n",
    "print(classification_report(y_test, prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.681274111145866\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(rf, X_test, y_test, cv=10)\n",
    "print(\"Random Forest:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:28:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy 0.7182080924855492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67       671\n",
      "           1       0.69      0.84      0.75       713\n",
      "\n",
      "    accuracy                           0.72      1384\n",
      "   macro avg       0.73      0.71      0.71      1384\n",
      "weighted avg       0.73      0.72      0.71      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_xgb = xgb.fit(X_train,y_train)\n",
    "prediction_xgb = model_xgb.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_xgb, y_test))\n",
    "print(classification_report(y_test, prediction_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:31:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:31:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:31:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:32:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:32:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:34:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost: 0.6618027317276612\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(xgb, X_test, y_test, cv=10)\n",
    "print(\"XGBoost:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
    "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
    "(You can also use different text data which you want)\n",
    "\n",
    "Apply the listed clustering methods to the dataset:\n",
    "\n",
    "K means, \n",
    "DBSCAN,\n",
    "Hierarchical clustering. \n",
    "\n",
    "You can refer to of the codes from  the follwing link below. \n",
    "https://www.kaggle.com/karthik3890/text-clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your code here.\n",
    "import pandas as pd\n",
    "\n",
    "amazon_review = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
    "amazon_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-11b4241d39ad>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  amazon_review['Reviews'] = amazon_review['Reviews'].str.replace('[^\\w\\s]','')\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ttp0037\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    feel lucky found used phone u used hard phone ...\n",
       "1    nice phone nice grade pantach revue clean set ...\n",
       "2                                              pleased\n",
       "3          work good go slow sometimes good phone love\n",
       "4    great phone replace lost phone thing volume bu...\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_review['Reviews'] = amazon_review['Reviews'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "amazon_review['Reviews'] = amazon_review['Reviews'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "amazon_review['Reviews'] = amazon_review['Reviews'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "amazon_review['Reviews'] = amazon_review['Reviews'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "amazon_review['Reviews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can write you answer here. (No code needed)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

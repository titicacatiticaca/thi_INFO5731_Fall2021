{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
    "\n",
    "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
    "\n",
    "Algorithms:\n",
    "\n",
    "(1) MultinominalNB\n",
    "\n",
    "(2) SVM \n",
    "\n",
    "(3) KNN \n",
    "\n",
    "(4) Decision tree\n",
    "\n",
    "(5) Random Forest\n",
    "\n",
    "(6) XGBoost\n",
    "\n",
    "Evaluation measurement:\n",
    "\n",
    "(1) Accuracy\n",
    "\n",
    "(2) Recall\n",
    "\n",
    "(3) Precison \n",
    "\n",
    "(4) F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-09e80b698028>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_data = pd.read_csv('stsa-train.txt', sep = 'delimiter=', header = None, names = ['review'])\n",
      "<ipython-input-1-09e80b698028>:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_data = pd.read_csv('stsa-test.txt', sep = 'delimiter=', header = None, names = ['review'])\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# read dataset\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('stsa-train.txt', sep = 'delimiter=', header = None, names = ['review'])\n",
    "train_data = train_data['review'].str.split(' ', 1, expand = True)\n",
    "train_data.columns = ['sentiment', 'review']\n",
    "\n",
    "test_data = pd.read_csv('stsa-test.txt', sep = 'delimiter=', header = None, names = ['review'])\n",
    "test_data = test_data['review'].str.split(' ', 1, expand = True)\n",
    "test_data.columns = ['sentiment', 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>apparently reassembled from the cutting-room f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             review\n",
       "0         1  a stirring , funny and finally transporting re...\n",
       "1         0  apparently reassembled from the cutting-room f...\n",
       "2         0  they presume their audience wo n't sit still f...\n",
       "3         1  this is a visually stunning rumination on love...\n",
       "4         1  jonathan parker 's bartleby should have been t..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no movement , no yuks , not much of anything .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>we never really feel involved with the story ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>this is one of polanski 's best films .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                             review\n",
       "0         0     no movement , no yuks , not much of anything .\n",
       "1         0  a gob of drivel so sickly sweet , even the eag...\n",
       "2         0  gangs of new york is an unapologetic mess , wh...\n",
       "3         0  we never really feel involved with the story ,...\n",
       "4         1            this is one of polanski 's best films ."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ttp0037\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ttp0037\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stopword = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "def data_cleaning(text):\n",
    "  text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "  text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text)\n",
    "  tokens = re.split('\\W+',text)\n",
    "  text = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 13343)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>100minute</th>\n",
       "      <th>103minute</th>\n",
       "      <th>10course</th>\n",
       "      <th>10th</th>\n",
       "      <th>10thgrade</th>\n",
       "      <th>10year</th>\n",
       "      <th>10yearold</th>\n",
       "      <th>112minute</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>ziyi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombieland</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>élan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             100minute  103minute  10course  10th  10thgrade  10year  \\\n",
       "0  0.000000        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "1  0.048154        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "2  0.029784        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "3  0.049596        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "4  0.048782        0.0        0.0       0.0   0.0        0.0     0.0   \n",
       "\n",
       "   10yearold  112minute   12  ...  ziyi  zoe  zombie  zombieland  zone  \\\n",
       "0        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "1        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "2        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "3        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "4        0.0        0.0  0.0  ...   0.0  0.0     0.0         0.0   0.0   \n",
       "\n",
       "   zoning  zoom  zwick  zzzzzzzzz  élan  \n",
       "0     0.0   0.0    0.0        0.0   0.0  \n",
       "1     0.0   0.0    0.0        0.0   0.0  \n",
       "2     0.0   0.0    0.0        0.0   0.0  \n",
       "3     0.0   0.0    0.0        0.0   0.0  \n",
       "4     0.0   0.0    0.0        0.0   0.0  \n",
       "\n",
       "[5 rows x 13343 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting train_data into numerical usinf TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(analyzer = data_cleaning)\n",
    "X_train_tfidf = tfidf_vector.fit_transform(train_data['review'])\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# saving the td-idf values in a dataframe\n",
    "X_train_tfidf_df=pd.DataFrame(X_train_tfidf.toarray())\n",
    "X_train_tfidf_df.columns=tfidf_vector.get_feature_names()\n",
    "X_train_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1821, 6357)\n"
     ]
    }
   ],
   "source": [
    "# Converting test_data into numerical usinf TF-IDF\n",
    "X_test_tfidf = tfidf_vector.fit_transform(test_data['review'])\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning algorithms\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "svm = LinearSVC()\n",
    "knn = KNeighborsClassifier(n_neighbors=5,n_jobs=-1)\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5536, 13343) (5536,)\n",
      "(1384, 13343) (1384,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing vars (80% train and 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf_df, train_data['sentiment'].values, test_size = 0.2, random_state = 42)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7955202312138728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77       671\n",
      "           1       0.76      0.88      0.82       713\n",
      "\n",
      "    accuracy                           0.80      1384\n",
      "   macro avg       0.80      0.79      0.79      1384\n",
      "weighted avg       0.80      0.80      0.79      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_mnb = mnb.fit(X_train, y_train)\n",
    "prediction_mnb = model_mnb.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_mnb,y_test))\n",
    "print(classification_report(y_test,prediction_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinominalNB: 0.7247054530288813\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(mnb, X_test, y_test, cv=10)\n",
    "print(\"MultinominalNB:\",scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.791907514450867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       671\n",
      "           1       0.78      0.83      0.80       713\n",
      "\n",
      "    accuracy                           0.79      1384\n",
      "   macro avg       0.79      0.79      0.79      1384\n",
      "weighted avg       0.79      0.79      0.79      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_svm = svm.fit(X_train,y_train)\n",
    "prediction_svm = model_svm.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_svm, y_test))\n",
    "print(classification_report(y_test, prediction_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.7348034615785632\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(svm, X_test, y_test, cv=10)\n",
    "print(\"SVM:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.740606936416185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       671\n",
      "           1       0.74      0.77      0.75       713\n",
      "\n",
      "    accuracy                           0.74      1384\n",
      "   macro avg       0.74      0.74      0.74      1384\n",
      "weighted avg       0.74      0.74      0.74      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_knn = knn.fit(X_train,y_train)\n",
    "prediction_knn = model_knn.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_knn, y_test))\n",
    "print(classification_report(y_test, prediction_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.6675737670732979\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(knn, X_test, y_test, cv=10)\n",
    "print(\"KNN:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.661849710982659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64       671\n",
      "           1       0.66      0.71      0.68       713\n",
      "\n",
      "    accuracy                           0.66      1384\n",
      "   macro avg       0.66      0.66      0.66      1384\n",
      "weighted avg       0.66      0.66      0.66      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_dt = dt.fit(X_train,y_train)\n",
    "prediction_dt = model_dt.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_dt, y_test))\n",
    "print(classification_report(y_test, prediction_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.6105202794286312\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(dt, X_test, y_test, cv=10)\n",
    "print(\"Decision Tree:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7420520231213873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71       671\n",
      "           1       0.71      0.83      0.77       713\n",
      "\n",
      "    accuracy                           0.74      1384\n",
      "   macro avg       0.75      0.74      0.74      1384\n",
      "weighted avg       0.75      0.74      0.74      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_rf = rf.fit(X_train,y_train)\n",
    "prediction_rf = model_rf.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_rf, y_test))\n",
    "print(classification_report(y_test, prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.6835366489417163\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(rf, X_test, y_test, cv=10)\n",
    "print(\"Random Forest:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy 0.7182080924855492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67       671\n",
      "           1       0.69      0.84      0.75       713\n",
      "\n",
      "    accuracy                           0.72      1384\n",
      "   macro avg       0.73      0.71      0.71      1384\n",
      "weighted avg       0.73      0.72      0.71      1384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a model on the training data\n",
    "model_xgb = xgb.fit(X_train,y_train)\n",
    "prediction_xgb = model_xgb.predict(X_test)\n",
    "print('Accuracy %s' % accuracy_score(prediction_xgb, y_test))\n",
    "print(classification_report(y_test, prediction_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost: 0.6618027317276612\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score\n",
    "scores = cross_val_score(xgb, X_test, y_test, cv=10)\n",
    "print(\"XGBoost:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
    "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
    "(You can also use different text data which you want)\n",
    "\n",
    "Apply the listed clustering methods to the dataset:\n",
    "\n",
    "K means, \n",
    "DBSCAN,\n",
    "Hierarchical clustering. \n",
    "\n",
    "You can refer to of the codes from  the follwing link below. \n",
    "https://www.kaggle.com/karthik3890/text-clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your code here.\n",
    "import pandas as pd\n",
    "\n",
    "amazon_review = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
    "amazon_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-11b4241d39ad>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  amazon_review['Reviews'] = amazon_review['Reviews'].str.replace('[^\\w\\s]','')\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ttp0037\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    feel lucky found used phone u used hard phone ...\n",
       "1    nice phone nice grade pantach revue clean set ...\n",
       "2                                              pleased\n",
       "3          work good go slow sometimes good phone love\n",
       "4    great phone replace lost phone thing volume bu...\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_review['Reviews'] = amazon_review['Reviews'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "amazon_review['Reviews'] = amazon_review['Reviews'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "amazon_review['Reviews'] = amazon_review['Reviews'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "amazon_review['Reviews'] = amazon_review['Reviews'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "amazon_review['Reviews'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TF-IDF \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vects = tfidf_vect.fit_transform(amazon_review['Reviews'])\n",
    "terms= tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '0000',\n",
       " '00000',\n",
       " '000000',\n",
       " '0000000000',\n",
       " '00000000000',\n",
       " '0000000000finally',\n",
       " '0000000i',\n",
       " '000001']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to understand what kind of words generated as columns by BOW\n",
    "terms[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttp0037\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:792: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({5: 163558,\n",
       "         2: 181133,\n",
       "         3: 17213,\n",
       "         6: 2551,\n",
       "         4: 15841,\n",
       "         0: 11589,\n",
       "         8: 6622,\n",
       "         7: 9221,\n",
       "         1: 6112})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Means\n",
    "# using all processes jobs=-1 and k means++ for starting initilization advantage\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters = 9,init='k-means++', n_jobs = -1,max_iter=10000, random_state=50)\n",
    "model.fit(tfidf_vects)\n",
    "from collections import Counter\n",
    "Counter(model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster-center\n",
    "labels = model.labels_\n",
    "cluster_center=model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.31014554e-06, 5.52080515e-06, 4.02183142e-06, ...,\n",
       "        5.41501054e-06, 1.94193108e-06, 4.32056408e-06],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413840, 125121)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "bow = count_vect.fit_transform(amazon_review['Reviews'].values)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in CLUSTER  1\n",
      "Key features: ['excellent', 'product', 'phone', 'condition', 'recommend', 'good', 'seller', 'price']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top words in CLUSTER  2\n",
      "Key features: ['nice', 'phone', 'price', 'product', 'good', 'love', 'work', 'great']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top words in CLUSTER  3\n",
      "Key features: ['work', 'perfect', 'good', 'product', 'ok', 'like', 'excelent', 'great']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top words in CLUSTER  4\n",
      "Key features: ['good', 'phone', 'product', 'price', 'work', 'far', 'thanks', 'quality']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top words in CLUSTER  5\n",
      "Key features: ['great', 'phone', 'work', 'product', 'price', 'condition', 'buy', 'good']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top words in CLUSTER  6\n",
      "Key features: ['phone', 'great', 'work', 'good', 'one', 'like', 'battery', 'use']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top words in CLUSTER  7\n",
      "Key features: ['daughter', 'love', 'phone', 'bought', 'great', 'happy', 'work', 'gift']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Top words in each cluster\n",
    "topn_features = 8\n",
    "centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "for cluster_num in range(7):\n",
    "    key_features = [terms[i] for i in centroids[cluster_num, :topn_features]]\n",
    "    print('Top words in CLUSTER  '+ str(cluster_num + 1))\n",
    "    print('Key features:', key_features)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn import metrics\n",
    "silhouette_score = metrics.silhouette_score(tfidf_vects, model.labels_, metric='euclidean')\n",
    "silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "reviews = []\n",
    "for i in amazon_review['Reviews']:\n",
    "    reviews.append(str(i).split())\n",
    "\n",
    "import gensim\n",
    "w2v_model=gensim.models.Word2Vec(reviews, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-f18d8814ae96>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vector /= count\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vectors = []\n",
    "for i in reviews:\n",
    "    vector = np.zeros(100)\n",
    "    count = 0\n",
    "    for word in i:\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            vector += vec\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    vector /= count\n",
    "    vectors.append(vector)  \n",
    "vectors = np.array(vectors)\n",
    "vectors = np.nan_to_num(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Computing 200th Nearest neighbour distance\n",
    "minPts = 2*100\n",
    "\n",
    "# This function return the number in the array just greater than or equal to itself.\n",
    "def lower_bound(nums, target): \n",
    "    l, r = 0, len(nums) - 1\n",
    "    while l <= r:\n",
    "        mid = int(l + (r - l) / 2)\n",
    "        if nums[mid] >= target:\n",
    "            r = mid - 1\n",
    "        else:\n",
    "            l = mid + 1\n",
    "    return l\n",
    "\n",
    "# Returns the distance of 200th nearest neighbour\n",
    "def compute200thnearestneighbour(x, data): \n",
    "    dists = []\n",
    "    for val in data:\n",
    "        dist = np.sum((x - val) **2 ) \n",
    "        if(len(dists) == 200 and dists[199] > dist): \n",
    "            l = int(lower_bound(dists, dist)) \n",
    "            if l < 200 and l >= 0 and dists[l] > dist:\n",
    "                dists[l] = dist\n",
    "        else:\n",
    "            dists.append(dist)\n",
    "            dists.sort()\n",
    "            \n",
    "# Dist 199 contains the distance of 200th nearest neighbour.    \n",
    "    return dists[199]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the 200th nearest neighbour distance of some point the dataset:\n",
    "\n",
    "neighbor = []\n",
    "for val in vectors[:1000]:\n",
    "    neighbor.append(compute200thnearestneighbour(val, vectors[:1000]))\n",
    "neighbor.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting for the Elbow Method\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.title(\"Elbow Method\")\n",
    "plt.plot([x for x in range(len(neighbor))], neighbor)\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Distance of 200th Nearest Neighbour\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dear Professor,\n",
    "\n",
    "I don't know why I cannot run 3 code blocks below. \n",
    "I tried on laptop and desktop as well as google colab, but they didn't work out.\n",
    "It keeps running and running.\n",
    "I will reinstall the Jupiter Notebook or any environment later on.\n",
    "\n",
    "Thank you for your understanding!\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training DBSCAN\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "model = DBSCAN(eps = 3, min_samples = minPts, n_jobs=-1)\n",
    "model.fit(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_review['DBSCAN Cluster Labels'] = model.labels_\n",
    "\n",
    "# Finding the number of reviews in each cluster\n",
    "print(amazon_review.groupby(['DBSCAN Cluster Labels'])['Reviews'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering Hierarchical\n",
    "\n",
    "import scipy\n",
    "from scipy.cluster import hierarchy\n",
    "dendro=hierarchy.dendrogram(hierarchy.linkage(sent_vectors,method='ward'))\n",
    "\n",
    "# cut at 30 to get 5 clusters\n",
    "plt.axhline(y=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can write you answer here. (No code needed)\n",
    "'''\n",
    "K-means clustering uses a pre-specified  number of clusters, so it specilize different sizes and shapes clusters.\n",
    "\n",
    "DBSCAN works on density and clusters points are densely packed together and labels the other points as noise.\n",
    "\n",
    "Hierarchical clustering: ease of handling of any forms similarity or distance. It gives a visual indication of how clusters relate each other.\n",
    "'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

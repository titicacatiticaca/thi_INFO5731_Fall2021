{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The third In-class-exercise (9/15/2021, 40 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
    "\n",
    "'''\n",
    "Please write you answer here:\n",
    "- I would like to do the research about how the Covid-19 impacts to small business, especial shipping industry.\n",
    "- I will to collect the daily sale / weekly sale / monthly sale data.\n",
    "- It depends on the data they have, I need atleast 1 year (Jun 2020 to Jun 2021) data for the research because I will compare the revenue during the Covid and after we got vaccine, and predict for the last 3 months of 2021.\n",
    "- I will use the BeautifulSoup library in Python to do web scraping.\n",
    "  + Download the web page containing the shipping transaction and using BeautifulSoup class to parse the page.\n",
    "  + Extracting information from the page.\n",
    "  + Combining the data into a Pandas Dataframe.\n",
    "  + Save Dataframe as csv file.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 (10 points): Write python code to collect 1000 reviews of a movie from IMDB (https://www.imdb.com/) or 1000 reviews of a product from Amazon (https://www.amazon.com/).\n",
    "\n",
    "As for the IMDB movie review, the following informtion need to be collected (for example: https://www.imdb.com/title/tt6751668/reviews?ref_=tt_urv):\n",
    "\n",
    "(1) User name\n",
    "\n",
    "(2) Star\n",
    "\n",
    "(3) Review title\n",
    "\n",
    "(4) Review text\n",
    "\n",
    "(5) Review posted time\n",
    "\n",
    "\n",
    "As for the Amazon product review, the following information need to be collected (for example: https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646/ref=sr_1_3?crid=2E3C55VKJX0K3&dchild=1&keywords=machine+learning+andrew+ng&qid=1631718619&sr=8-3):\n",
    "\n",
    "(1) User name\n",
    "\n",
    "(2) Star\n",
    "\n",
    "(3) Review title\n",
    "\n",
    "(4) Review text\n",
    "\n",
    "(5) Review posted time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4uorermtiqhejcxxxgs753i36t52q343emt37poa3eoqp2qrkohk7kltmzf7kbzb3zuo3in', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4v6lermtiqhejcxxxgs753i36t52q343epdv7xob7b6qpyeoojn7bta5fc3n4r4jbuitv4d', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4s6rermtiqhejcxxxgs753i36t52q343uptv7xjb3b6qp6w2fzr75g2hftrup5qwdbtbceh', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6hcbsqyxckisbvlwrrzdx2o2ysetztqpdr4hob7dpeqam3d3xk6eplzptkc7jb7k6ujacuu', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6lbjsqyxckisbvlwrrzdx2o2ysetztqpdr4pmb3apsqams3kgktcmk7ofxutghefsy2dd4u', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6ncbsqyxckisbvlwrrzdx2o2ysetztqpdx7hnahc7sqambe56smouxqx44zbjwt52vs5mly', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6rbjsqyxckisbvlwrrzdx2o2ysetztqptv4pjaddpsqam5k3u36ulnckbv4aena3b2npsna', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xohcbsqyxckisbvlwrrzdx2o2ysetztqpd37ppadc7qqamhuforw5veulixm2j2ihpa2ij2y', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xolbjsqyxckisbvlwrrzdx2o2ysetztqpdd7hnaha7gqamfqcmmhgxrcm5wq72w4lvayy2qi', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xondzsqyxckisbvlwrrzdx2o2ysetztqpdr77lade7sqamzwic5xh35albdc25rtnkcatd34', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xorbbsqyxckisbvlwrrzdx2o2ysetztqpdr4hma7cpuqam6j4vynfbktmijbqs5vkokywrj4', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4x6hdzsqyxckisbvlwrrzdx2o2ysetztqpdr4hoa3d72qamoxng7fkoepfrnbr6dqp3wzzppi', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4x6lbbsqyxckisbvlwrrzdx2o2ysetztqmdx6xpapc7uqamgep7ou47zeydxnskt3v7ony4de', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4x6ndzsqyxckisbvlwrrzdx2o2ysetztqpdx7xmahbpuqam3b653euya2saxy6tultg3hljam', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4x6rbbsqyxckisbvlwrrzdx2o2ysetztqpdr4hpapep2qam2kw7msgwpqy3x7xrtkhuacvn4y', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4uohdzsqyxckisbvlwrrzdx2o2ysetztqpdr77kapapqqamiv2ug4uwbb3oilcl3us5bkxqka', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4uolbbsqyxckisbvlwrrzdx2o2ysetztqpdx67ea7dpgqamakmstxujmdfmluh6ck4kb3hooq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4uondzsqyxckisbvlwrrzdx2o2ysetztqpdr77jadc7gqamlnc5rm734wtsbljqyojtdodufi', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4uorbbsqyxckisbvlwrrzdx2o2ysetztqmt76xfala7eqam5jrgwrbzf6wwp4velmraiycyri', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4u6hdzsqyxckisbvlwrrzdx2o2ysetztqpdx6piatbpuqamhspn3osr6e257niakbmrnqgeqy', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4u6lbbsqyxckisbvlwrrzdx2o2ysetztqpdr77jadc7wqamhjltuh3ttvgxr25ad6pboidkkm', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4u6ndzsqyxckisbvlwrrzdx2o2ysetztqpdr4hpb3b7eqamolrv6dxno4fw74dyifj64ardpq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4u6rbbsqyxckisbvlwrrzdx2o2ysetztqmtb7hfb7dp6qam3y2qzqkqi3cxj47gnrbhlzvo2m', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4vohdzsqyxckisbvlwrrzdx2o2ysetztqpdr4peade7qqamjjtjzqf3ogphzen5t3d4vrrmra', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4volbbsqyxckisbvlwrrzdx2o2ysetztqpdx6hlatcpgqamvoelfkeorf6erdjuyao4veycz4', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4vondzsqyxckisbvlwrrzdx2o2ysetztqpdx6hnadapyqamxvtu6kzflhnk53vpzshcacvgwy', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4vorbbsqyxckisbvlwrrzdx2o2ysetztqpd36xmb3cp2qamtqx4bmqwoc7ln5zowocl6kld6y', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4v6hdzsqyxckisbvlwrrzdx2o2ysetztqpdx7pmapdpsqamnzhnqrrcr4pw5yd3lvh3kitha4', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4v6lbbsqyxckisbvlwrrzdx2o2ysetztqpd36pma7ep2qam4jnmzpcjwcih6fcdy4s6obs4ma', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4v6ndzsqyxckisbvlwrrzdx2o2ysetztqpd37hoada7gqamedqmxtayqc4gem234ucfly3rbm', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4v6rbbsqyxckisbvlwrrzdx2o2ysetztqpd367naxd76qammubhxi55rxnx23e5zkml3gs4ua', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4sohdrsqyxckisbvlwrrzdx2o2ysetztqpdr77jape7uqamxau6io5uxl7vpazxrrdowap4ee', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4solczsqyxckisbvlwrrzdx2o2ysetztqpdr77kalap2qamnrra6h7kie74ktkvu6dqhisnge', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4sondrsqyxckisbvlwrrzdx2o2ysetztqmtz6pkapb7wqamiwqbndrdgidx2ighor6fusnz6m', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4sorczsqyxckisbvlwrrzdx2o2ysetztqpdx7hnahbpuqamhyi3vflfodgtftdfc635oppzpq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4s6hdrsqyxckisbvlwrrzdx2o2ysetztqpdr4pmapc7sqamamvselenmr2nfgk4ybqbbfzwra', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4s6lczsqyxckisbvlwrrzdx2o2ysetztqpdr4hnada7gqamqz7svmp6jdfwr4tmgnxgac2fre', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4s6ndrsqyxckisbvlwrrzdx2o2ysetztqpdr77kb3apgqamlkgjvzpv4snpiuown44al6tlrq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4s6rczsqyxckisbvlwrrzdx2o2ysetztqmtx4pnb3dp6qamr4sim3blrzkmigzg2xeuyjnwyy', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6ddrotazcw5khxt5dru3ezs4zwrritfntx6peatepgwttawcktvtydmjyl7hnw3oialpnk7ya', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6dcbltazcw5khxt5dru3ezs4zwrritfntx6plahc7qultaxraiuiqcg65pnlhp4wrphxkd6ga', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6dczotazcw5khxt5dru3ezs4zwrritfntv7hiatc7yvdtaurjqo6r322qgmlp2oh3vqupn7yq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6dbjltazcw5khxt5dru3ezs4zwrritfntx6xiatc7wultavzak3jcqayvlyeduagock3ptjxa', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6bdrotazcw5khxt5dru3ezs4zwrritfntx4hmb3c7swttawa7j67ddxoztm6fjul6ubptjoha', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6bcbltazcw5khxt5dru3ezs4zwrritfntx6peaxb72wttavd5lcsk6rjvjjo6kgdxenvzirlq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6bczotazcw5khxt5dru3ezs4zwrritfntx67oada7eultawjp634x2ckemvmktlmukpdj562q', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6bbjltazcw5khxt5dru3ezs4zwrritfnt37pkale7yu3taubrpdasaf5l2r6rpi74frccldsq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6hdrotazcw5khxt5dru3ezs4zwrritfntx6pea3dpgvltaux57iovjxovdwfqwyt74f7xtdwq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6hcbltazcw5khxt5dru3ezs4zwrritfntx6pea7d74wttavstg665w6faijftirpra6n6xmfa', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6hczotazcw5khxt5dru3ezs4zwrritfntx6plada72u3tawb6mqqdbdqugpyezelomek4yima', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6hbjltazcw5khxt5dru3ezs4zwrritfntx6xla7e7uultaxt2c6c6kq4ixwppfglwvmijgkra', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6fdrotazcw5khxt5dru3ezs4zwrritfnt377ealep6vdtaw24agesea5toeiy6tis3rjoz2wq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6fcbltazcw5khxt5dru3ezs4zwrritfnt377ma3bpevltauf7oagisljegs6ws5rau4gljm5a', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6fczotazcw5khxt5dru3ezs4zwrritfntx6peaxbpqwttawlxch4bhnrszzhrtdpipawnndwq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6fbjltazcw5khxt5dru3ezs4zwrritfntx6xmapbpyuttav4cubqawwgg23woag4gtf3zzxdq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6ldrotazcw5khxt5dru3ezs4zwrritfntx6xkahcpuw3taujvtrfta2fsyy2v5l7b35hqj3xa', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6lcbltazcw5khxt5dru3ezs4zwrritfntx6pladcp2u3tavq7jqnshi7whxlr7tftrsmdnlea', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6lczotazcw5khxt5dru3ezs4zwrritfntx67lapd7eudtauhzq5jmpopqcsi77pqguxmsepva', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6lbjltazcw5khxt5dru3ezs4zwrritfntx6plalepeuttawx536gd3cq5i7utjaz3wkxxuynq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6jdrotazcw5khxt5dru3ezs4zwrritfntx6pladd72vttawgaliyegqyl4vuanmzpknzovtgq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6jcbltazcw5khxt5dru3ezs4zwrritfntv7pob3epqv3tavpfc4ychwyj4cyibwzw4xuvbcxa', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6jczotazcw5khxt5dru3ezs4zwrritfntx6plade7qu3tavr63jdbkgwah7krte6vxft6lsda', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6jbjltazcw5khxt5dru3ezs4zwrritfntx6xmaxepeudtau7j3mrvc6o5pvvtydzvs2dtpiga', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6pdrotazcw5khxt5dru3ezs4zwrritfntx67la7b7wvltaxhapft457qtxw4sb75p6dudqoga', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6pcbltazcw5khxt5dru3ezs4zwrritfntx6peb3e76vltawn5rjvpgstcnzfszdaxirdhepua', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6pczotazcw5khxt5dru3ezs4zwrritfntx6xeahcp6ultaxcj2his57we6jj53ctfj7y3cw2q', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6pbjltazcw5khxt5dru3ezs4zwrritfntx6pea7epwultawcfivm5qzq3gl5oap3cwzg5mazq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6ndrotazcw5khxt5dru3ezs4zwrritfntx6pea3bp6u3taveruni56tr7rooxgdzzhgm5fpxq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6ncbltazcw5khxt5dru3ezs4zwrritfntx6pladcp6w3tavn4brdh5gy4jlvvnnjnfvlfceqq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6nczotazcw5khxt5dru3ezs4zwrritfntx6peb3a7yvdtaws72imk4fwgj4jdw3enbuzbtida', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6nbjltazcw5khxt5dru3ezs4zwrritfntx6plb3d7qvltav7jknbg6smlcwkdezfgvc7fpfdq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6tdrotazcw5khxt5dru3ezs4zwrritfntx6pfb3a7uv3tau63sc6des7agpxoabvrkfygnjrq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6tcbltazcw5khxt5dru3ezs4zwrritfntx6xnb3dpewttawvvgmbp4h665vfhc2xozsr3bx4q', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6tczotazcw5khxt5dru3ezs4zwrritfntx6pladdpyw3tawzdgiq4pmilfla3aghbdc7fggma', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6tbjltazcw5khxt5dru3ezs4zwrritfnt34hlahepgultaxhswunl7h3ogr3laaqeflseypoa', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6rdrotazcw5khxt5dru3ezs4zwrritfntx6plaha7qvltaurkbxxsad5jvh4l77zd5cmjx4oa', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6rcbltazcw5khxt5dru3ezs4zwrritfntx6plahepgvltaxinjlvvlf7h6awwbrkftgobzfia', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6rczotazcw5khxt5dru3ezs4zwrritfntx6plb3epgwttawiqlop5h7544436kyb47brfqkua', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4w6rbjltazcw5khxt5dru3ezs4zwrritfntx6xoaxa7swttavpvhgg4a7hhcb3prydelm2245ba', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xoddrotazcw5khxt5dru3ezs4zwrritfntx6plb7d7uvttaxwpwbyqcpm6uzzwf5ac6l4xf73a', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xodcbltazcw5khxt5dru3ezs4zwrritfntz6heb3d7gudtaxwl3szwmxkoatuilonevav6cf2a', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xodczotazcw5khxt5dru3ezs4zwrritfntz4hna3bp2vttaxfzzksesseguvodeg2vgxv3wzla', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xodbjltazcw5khxt5dru3ezs4zwrritfntx6peatb7gvdtav3vjptx4wijytulkwejosddyylq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xobdrotazcw5khxt5dru3ezs4zwrritfntx6xiadc7eu3tavgupkp7bwlutor2j7hpnwkb5mfq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xobcbltazcw5khxt5dru3ezs4zwrritfntx6plala76uttavlgkxcxvdhb33rv3glya4b7tetq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xobczotazcw5khxt5dru3ezs4zwrritfntx6xmaxc76ultaxkati5smnfscgkbboxgoxj2g7ba', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xobbjltazcw5khxt5dru3ezs4zwrritfntx6pfalepeudtavxjxpcp63glp735fhthkcpzalxa', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xohdrotazcw5khxt5dru3ezs4zwrritfntx67ib3e72vttax226pcfpl2lyv45xbel6le4pfhq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xohcbltazcw5khxt5dru3ezs4zwrritfnt77xfa7dpeu3taxq7oro65z2mqvcw7lvay7g3wvfa', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xohczotazcw5khxt5dru3ezs4zwrritfntx6xmala7qwttaucmz2ck3tvjzjiirya3wu73tqla', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xohbjltazcw5khxt5dru3ezs4zwrritfnt37peape74udtavknq5dq6w5cjlpoqmotedqdp3sq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xofdrntazcw5khxt5dru3ezs4zwrritfntz6xla3apqu3taxfb3jchgz7zu2nendnb4cuvnaia', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xofcbktazcw5khxt5dru3ezs4zwrritfntx6peapepqudtaxkgcc7vjlp42wfdu3aogu25xorq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xofczntazcw5khxt5dru3ezs4zwrritfntx6xnahap2vltavox5av6j6e7xv2ptq6vjd7iy7za', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xofbjktazcw5khxt5dru3ezs4zwrritfntx6pladb7sv3tauw36dcw24jzg6nq3ch6zorofhfq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xoldrntazcw5khxt5dru3ezs4zwrritfntx6plahd7uvdtau5aja4grvxnot6ilty7w2lsc7ga', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xolcbktazcw5khxt5dru3ezs4zwrritfntx6pladd7yv3tax3epjf7qxy7onhpnochwsg7rota', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xolczntazcw5khxt5dru3ezs4zwrritfntx6peaxdpqudtaux74d7ztqgfwyicmaow4wddkaxq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xolbjktazcw5khxt5dru3ezs4zwrritfntx6pea7cpqwttaxvqzeldbkatkvscv3msxvb6kijq', 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey=g4xojdrntazcw5khxt5dru3ezs4zwrritfntx6pfata7uu3tavzu3otadxzz32cffjq4uywgu43q']\n"
     ]
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "\n",
    "#import the library used to query a website\n",
    "import urllib.request\n",
    "import requests\n",
    "\n",
    "#import the Beautiful soup functions to parse the data returned from the website\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "session = requests.Session()\n",
    "url = 'https://www.imdb.com/title/tt0499549/reviews'\n",
    "\n",
    "#Query the website and return the html to the variable 'page'\n",
    "page = session.get(url)\n",
    "\n",
    "#Parse the html in the 'page' variable, and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Find key of load-more pages\n",
    "key = soup.find('div', {'class':'load-more-data'})\n",
    "datakey = key.attrs['data-key']\n",
    "\n",
    "# Request to continue to get next-page key\n",
    "loadmore_url_list = []\n",
    "a = True\n",
    "while a:\n",
    "    if key is None:\n",
    "        print('error')\n",
    "        a = False\n",
    "    else:\n",
    "        loadmore_url = 'https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey='+datakey\n",
    "        get_loadmore = session.get(loadmore_url)\n",
    "        res_loadmore = BeautifulSoup(get_loadmore.content, 'html.parser')\n",
    "        key = res_loadmore.find('div', {'class':'load-more-data'})\n",
    "        datakey = key.attrs['data-key']\n",
    "        loadmore_url_list.append('https://www.imdb.com/title/tt0499549/reviews/_ajax?ref_=undefined&paginationKey='+datakey)\n",
    "        if len(loadmore_url_list) == 100: # need 40 urls to find around 1000 reviews, then stop\n",
    "            break\n",
    "print(loadmore_url_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all urls, including urls in host and next pages, which will be using\n",
    "url = 'https://www.imdb.com/title/tt0499549/reviews'\n",
    "all_urls=[]\n",
    "all_urls.append(url)\n",
    "all_urls.extend(loadmore_url_list)\n",
    "\n",
    "review_elements = []\n",
    "for url in all_urls:\n",
    "    request = urllib.request.urlopen(url)\n",
    "    webpage  = request.read()\n",
    "    soup = BeautifulSoup(webpage)\n",
    "\n",
    "    reviews = soup.find_all(\"div\", {\"class\":\"lister-item-content\" })\n",
    "    for review in reviews:        \n",
    "        try:\n",
    "            username = review.find (\"span\", class_=\"display-name-link\").get_text()\n",
    "        except:\n",
    "            username = \"\"\n",
    "        try:\n",
    "            rating = review. find (\"span\", class_=\"rating-other-user-rating\").getText().strip()\n",
    "        except:\n",
    "            rating = \"\"\n",
    "        try:\n",
    "            review_title = review.find(\"a\", class_=\"title\").text.strip()\n",
    "        except:\n",
    "            review_title = \"\"\n",
    "        try:\n",
    "            review_text = review.find (\"div\", class_=\"text show-more__control\").get_text()\n",
    "        except:\n",
    "            review_text =\"\"\n",
    "        try:\n",
    "            review_date = review.find(\"span\", class_=\"review-date\").get_text()\n",
    "        except:\n",
    "            review_date = \"\"\n",
    "\n",
    "    review_elements.append([username, rating, review_title, review_text, review_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunwarrior13</td>\n",
       "      <td>10/10</td>\n",
       "      <td>More Impressive On Technical Level Than Storyt...</td>\n",
       "      <td>Avatar is an epic science fiction film written...</td>\n",
       "      <td>2 March 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chrysanthepop</td>\n",
       "      <td></td>\n",
       "      <td>Pocahontas in A Moon</td>\n",
       "      <td>After more than a decade, James Cameron makes ...</td>\n",
       "      <td>15 April 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipemanuelneto</td>\n",
       "      <td>8/10</td>\n",
       "      <td>Visually extraordinary, with excellent cinemat...</td>\n",
       "      <td>I confess that this film never really caught m...</td>\n",
       "      <td>4 December 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dfranzen70</td>\n",
       "      <td>5/10</td>\n",
       "      <td>Incredible, inventive effects can't save this</td>\n",
       "      <td>James Cameron's long-awaited Titanic follow-up...</td>\n",
       "      <td>29 December 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonny_Numb</td>\n",
       "      <td>8/10</td>\n",
       "      <td>Cameron's Visual Dazzle Saves Familiar Story</td>\n",
       "      <td>At this point, the smothering hype machine has...</td>\n",
       "      <td>13 January 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>drewfamilyman</td>\n",
       "      <td>10/10</td>\n",
       "      <td>Duh !!!</td>\n",
       "      <td>I had been wanting to see Avatar since I heard...</td>\n",
       "      <td>20 December 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>markneeleman000</td>\n",
       "      <td>3/10</td>\n",
       "      <td>I did NOT like this movie.</td>\n",
       "      <td>In this age of pulp it's hardly surprising thi...</td>\n",
       "      <td>30 December 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Gumnutblossom</td>\n",
       "      <td>6/10</td>\n",
       "      <td>Amazing special effects, but was way too long.</td>\n",
       "      <td>When I saw this movie, I was so-so about what ...</td>\n",
       "      <td>26 December 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>hsreviewonlinereviews</td>\n",
       "      <td>5/10</td>\n",
       "      <td>The Star Wars Of Our Generation</td>\n",
       "      <td>James Cameron's \"Avatar\" was mind-blowing, and...</td>\n",
       "      <td>17 January 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>shy-guy-27</td>\n",
       "      <td>10/10</td>\n",
       "      <td>One of the finest films ever made</td>\n",
       "      <td>Surprise, surprise. Another user posting a rev...</td>\n",
       "      <td>15 May 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  username rating  \\\n",
       "0             sunwarrior13  10/10   \n",
       "1            Chrysanthepop          \n",
       "2         filipemanuelneto   8/10   \n",
       "3               dfranzen70   5/10   \n",
       "4               Jonny_Numb   8/10   \n",
       "..                     ...    ...   \n",
       "96           drewfamilyman  10/10   \n",
       "97         markneeleman000   3/10   \n",
       "98           Gumnutblossom   6/10   \n",
       "99   hsreviewonlinereviews   5/10   \n",
       "100             shy-guy-27  10/10   \n",
       "\n",
       "                                          review_title  \\\n",
       "0    More Impressive On Technical Level Than Storyt...   \n",
       "1                                 Pocahontas in A Moon   \n",
       "2    Visually extraordinary, with excellent cinemat...   \n",
       "3        Incredible, inventive effects can't save this   \n",
       "4         Cameron's Visual Dazzle Saves Familiar Story   \n",
       "..                                                 ...   \n",
       "96                                             Duh !!!   \n",
       "97                          I did NOT like this movie.   \n",
       "98      Amazing special effects, but was way too long.   \n",
       "99                     The Star Wars Of Our Generation   \n",
       "100                  One of the finest films ever made   \n",
       "\n",
       "                                           review_text       review_date  \n",
       "0    Avatar is an epic science fiction film written...      2 March 2012  \n",
       "1    After more than a decade, James Cameron makes ...     15 April 2010  \n",
       "2    I confess that this film never really caught m...   4 December 2020  \n",
       "3    James Cameron's long-awaited Titanic follow-up...  29 December 2009  \n",
       "4    At this point, the smothering hype machine has...   13 January 2010  \n",
       "..                                                 ...               ...  \n",
       "96   I had been wanting to see Avatar since I heard...  20 December 2009  \n",
       "97   In this age of pulp it's hardly surprising thi...  30 December 2009  \n",
       "98   When I saw this movie, I was so-so about what ...  26 December 2009  \n",
       "99   James Cameron's \"Avatar\" was mind-blowing, and...   17 January 2010  \n",
       "100  Surprise, surprise. Another user posting a rev...       15 May 2010  \n",
       "\n",
       "[101 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine them together into Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(review_elements, columns=[\"username\", \"rating\", \"review_title\", \"review_text\", \"review_date\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Avatar_reviews.csv\", \"w\", newline=\"\", encoding='utf-8') as file:\n",
    "    df.to_csv(file)\n",
    "with open(\"Avatar_reviews.csv\", \"r\", encoding='utf-8') as file:\n",
    "    pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/). \n",
    "\n",
    "The following information of the article needs to be collected:\n",
    "\n",
    "(1) Title\n",
    "\n",
    "(2) Venue/journal/conference being published\n",
    "\n",
    "(3) Year\n",
    "\n",
    "(4) Authors\n",
    "\n",
    "(5) Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "\n",
    "#import the library used to query a website\n",
    "import urllib.request\n",
    "import requests\n",
    "\n",
    "#import the Beautiful soup functions to parse the data returned from the website\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "session = requests.Session()\n",
    "url = 'https://www.semanticscholar.org/paper/[Breast-cancer].-Iwase/9bb005f04021f8efce2d593a15b53dd4fa087a6d#related-papers'\n",
    "#Query the website and return the html to the variable 'page'\n",
    "page = session.get(url)\n",
    "\n",
    "#Parse the html in the 'page' variable, and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publisher(soup):\n",
    "    # create a publisher list\n",
    "    publish_list = []\n",
    "  \n",
    "    # find the html tag, convert to string and store to the list\n",
    "    for i in soup.find_all(\"span\", class_=\"cl-paper-venue\"):\n",
    "        publish_list.append(i.get_text())\n",
    "    return publish_list\n",
    "\n",
    "def year(soup):    \n",
    "    # create a year list\n",
    "    year_list = []\n",
    "  \n",
    "    # find the html tag, convert to string and save to the list\n",
    "    for i in soup.find_all(\"span\", class_=\"cl-paper-pubdates\"):\n",
    "        year_list.append(i.get_text())\n",
    "    return year_list\n",
    "\n",
    "def authors(soup):    \n",
    "    # create a author list\n",
    "    authors_list = []\n",
    "  \n",
    "    # find the html tag, convert to string and store to the list\n",
    "    for i in soup.find_all(\"span\", class_=\"cl-paper-authors\"):\n",
    "        authors_list.append(i.get_text())\n",
    "    return authors_list\n",
    "\n",
    "def abstract(soup):    \n",
    "    # create an abstract list\n",
    "    abstract_list = []\n",
    "  \n",
    "    # find the html tag, convert to string and store to the list\n",
    "    for i in soup.find_all(\"div\", class_=\"tldr-abstract-replacement text-truncator\"):\n",
    "        abstract_list.append(i.get_text())\n",
    "    return abstract_list\n",
    "\n",
    "art_title = title(soup)\n",
    "art_publisher = publisher(soup)\n",
    "art_year = year(soup)\n",
    "art_authors = authors(soup)\n",
    "art_abstract = abstract(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Systematic Review of Fear of Cancer Recurren...</td>\n",
       "      <td>Frontiers in Psychology</td>\n",
       "      <td>Kate Anderson, A. Smith, +9 authors G. Garvey</td>\n",
       "      <td>2021</td>\n",
       "      <td>TLDRThe findings of this review highlight diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dancing With Health: Quality of Life and Physi...</td>\n",
       "      <td>Frontiers in Psychology</td>\n",
       "      <td>V. Karkou, Irene Dudley-Swarbrick, +19 authors...</td>\n",
       "      <td>2021</td>\n",
       "      <td>TLDRDancing with Health is a multi-site pilot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Defined Mathematical Relationships Among Cance...</td>\n",
       "      <td>Frontiers in Cell and Developmental Biology</td>\n",
       "      <td>G. Manzo</td>\n",
       "      <td>2020</td>\n",
       "      <td>TLDRThis work provides further support for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SIRT7 Is a Prognostic Biomarker Associated Wit...</td>\n",
       "      <td>Frontiers in Oncology</td>\n",
       "      <td>Qin Huo, Zhenwei Li, L. Cheng, Fan Yang, Ni Xie</td>\n",
       "      <td>2020</td>\n",
       "      <td>TLDRIt is demonstrated that the high expressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Generalization of Conscious Attentional Av...</td>\n",
       "      <td>Frontiers in Psychology</td>\n",
       "      <td>D. Ng, R. Fielding, W. Lam</td>\n",
       "      <td>2020</td>\n",
       "      <td>TLDRWomen with high anxiety generalized consci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Outcomes of breast cancer management from an U...</td>\n",
       "      <td>Indian Journal of Medical and Paediatric Oncology</td>\n",
       "      <td>N. Mullapudi, Kabeer Kirti, Naveen Padmanaban,...</td>\n",
       "      <td>2019</td>\n",
       "      <td>TLDRThe study reflects a higher percentage of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Similarities Between Embryo Development and Ca...</td>\n",
       "      <td>Front. Cell Dev. Biol.</td>\n",
       "      <td>G. Manzo</td>\n",
       "      <td>2019</td>\n",
       "      <td>TLDRCSCs would be equivalent to para-embryonic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Breast cancer risk assessment using the Gail m...</td>\n",
       "      <td>Asian Pacific journal of cancer prevention : A...</td>\n",
       "      <td>N. Erbil, N. Dundar, Ç. Inan, Nurgul Bolukbas</td>\n",
       "      <td>2015</td>\n",
       "      <td>TLDRThe breast cancer risk assessment tool can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Design, synthesis and bioevaluation of novel 6...</td>\n",
       "      <td>European journal of medicinal chemistry</td>\n",
       "      <td>A. Jha, Y. Yadav, +8 authors T. S. Cameron</td>\n",
       "      <td>2015</td>\n",
       "      <td>TLDRThe compounds displayed well-acceptable dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The level of knowledge, attitude and practice ...</td>\n",
       "      <td>None</td>\n",
       "      <td>F. Akuffo</td>\n",
       "      <td>2014</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  A Systematic Review of Fear of Cancer Recurren...   \n",
       "1  Dancing With Health: Quality of Life and Physi...   \n",
       "2  Defined Mathematical Relationships Among Cance...   \n",
       "3  SIRT7 Is a Prognostic Biomarker Associated Wit...   \n",
       "4  The Generalization of Conscious Attentional Av...   \n",
       "5  Outcomes of breast cancer management from an U...   \n",
       "6  Similarities Between Embryo Development and Ca...   \n",
       "7  Breast cancer risk assessment using the Gail m...   \n",
       "8  Design, synthesis and bioevaluation of novel 6...   \n",
       "9  The level of knowledge, attitude and practice ...   \n",
       "\n",
       "                                           publisher  \\\n",
       "0                            Frontiers in Psychology   \n",
       "1                            Frontiers in Psychology   \n",
       "2        Frontiers in Cell and Developmental Biology   \n",
       "3                              Frontiers in Oncology   \n",
       "4                            Frontiers in Psychology   \n",
       "5  Indian Journal of Medical and Paediatric Oncology   \n",
       "6                             Front. Cell Dev. Biol.   \n",
       "7  Asian Pacific journal of cancer prevention : A...   \n",
       "8            European journal of medicinal chemistry   \n",
       "9                                               None   \n",
       "\n",
       "                                             authors  year  \\\n",
       "0      Kate Anderson, A. Smith, +9 authors G. Garvey  2021   \n",
       "1  V. Karkou, Irene Dudley-Swarbrick, +19 authors...  2021   \n",
       "2                                           G. Manzo  2020   \n",
       "3    Qin Huo, Zhenwei Li, L. Cheng, Fan Yang, Ni Xie  2020   \n",
       "4                         D. Ng, R. Fielding, W. Lam  2020   \n",
       "5  N. Mullapudi, Kabeer Kirti, Naveen Padmanaban,...  2019   \n",
       "6                                           G. Manzo  2019   \n",
       "7      N. Erbil, N. Dundar, Ç. Inan, Nurgul Bolukbas  2015   \n",
       "8         A. Jha, Y. Yadav, +8 authors T. S. Cameron  2015   \n",
       "9                                          F. Akuffo  2014   \n",
       "\n",
       "                                            abstract  \n",
       "0  TLDRThe findings of this review highlight diff...  \n",
       "1  TLDRDancing with Health is a multi-site pilot ...  \n",
       "2  TLDRThis work provides further support for the...  \n",
       "3  TLDRIt is demonstrated that the high expressio...  \n",
       "4  TLDRWomen with high anxiety generalized consci...  \n",
       "5  TLDRThe study reflects a higher percentage of ...  \n",
       "6  TLDRCSCs would be equivalent to para-embryonic...  \n",
       "7  TLDRThe breast cancer risk assessment tool can...  \n",
       "8  TLDRThe compounds displayed well-acceptable dr...  \n",
       "9                                               None  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine data into Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "papers = dict(title = art_title, publisher = art_publisher, authors = art_authors, year = art_year, abstract = art_abstract)\n",
    "papers = pd.DataFrame.from_dict(papers, orient='index')\n",
    "papers = papers.transpose()\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Articles.csv\", \"w\", newline=\"\", encoding='utf-8') as file:\n",
    "    df.to_csv(file)\n",
    "with open(\"Articles.csv\", \"r\", encoding='utf-8') as file:\n",
    "    pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
    "\n",
    "The following information needs to be collected:\n",
    "\n",
    "(1) User_name\n",
    "\n",
    "(2) Posted time\n",
    "\n",
    "(3) Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from tweepy) (1.15.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from tweepy) (2.25.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (2020.12.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\ttp0037\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "!pip install tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import tweepy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_search(consumer_key, consumer_secret, access_token, access_token_secret, hashtag):\n",
    "  \n",
    "    # create authentication for accessing Twitter\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    # initialize Tweepy API\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "      # get the name of the spreadsheet we will write to\n",
    "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag))\n",
    "\n",
    "      # will collect 1000 posts\n",
    "    numtweet = int(input('Enter the number of tweets that you want to collect: '))\n",
    "\n",
    "      # open the spreadsheet we will write to\n",
    "    with open('%s.csv' % (fname), 'w') as file:\n",
    "        w = csv.writer(file)\n",
    "      \n",
    "          # write header row to spreadsheet\n",
    "        w.writerow(['posted time', 'tweet text', 'user_name'])\n",
    "\n",
    "      # for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
    "      # \n",
    "        for tweet in tweepy.Cursor(api.search, q=hashtag+' -filter:retweets', lang=\"en\", tweet_mode='extended').items(numtweet):\n",
    "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8')])\n",
    "                                                                                                                           \n",
    "                            \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer Key:  p1bzwj5wvp6EWgBy9jvaN3llq\n",
      "Consumer Secret: MijsahV7ncQ4nvBDZN34YVXoDZ6a5buSmng7Kt1caJ4hMDfh9Z\n",
      "Access Token: 393052525-Nya0ZQ2l8fvUHjgbfUxuQeaLcJzI95QMhX9XFuup\n",
      "Access Token Secret: N8194oujcZmw676PaoiPrRk5rKax2CRl1yinyUGH8hvG2\n",
      "Enter the hashtag you want to scrape: #olympics2021\n",
      "Enter the number of tweets that you want to collect: 1000\n"
     ]
    }
   ],
   "source": [
    "consumer_key = input('Consumer Key:  ')\n",
    "consumer_secret= input('Consumer Secret: ')\n",
    "access_token = input('Access Token: ')\n",
    "access_token_secret = input('Access Token Secret: ')\n",
    "\n",
    "hashtag = input(\"Enter the hashtag you want to scrape: \")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    hashtag_search(consumer_key, consumer_secret, access_token, access_token_secret, hashtag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
